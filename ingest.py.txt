# ingest.py
from pathlib import Path
from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import FAISS

DOCS_DIR = "docs"
INDEX_DIR = "rag_index"

def load_docs():
    docs = []
    # PDFs
    pdf_loader = DirectoryLoader(DOCS_DIR, glob="**/*.pdf", loader_cls=PyPDFLoader)
    docs += pdf_loader.load()
    # Text / Markdown
    txt_loader = DirectoryLoader(DOCS_DIR, glob="**/*.txt", loader_cls=TextLoader)
    md_loader  = DirectoryLoader(DOCS_DIR, glob="**/*.md",  loader_cls=TextLoader)
    docs += txt_loader.load()
    docs += md_loader.load()
    return docs

def main():
    print("Loading documents...")
    docs = load_docs()
    print(f"Loaded {len(docs)} documents")

    print("Splitting into chunks...")
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=800, chunk_overlap=150, add_start_index=True
    )
    chunks = splitter.split_documents(docs)
    print(f"Created {len(chunks)} chunks")

    print("Computing embeddings (local via Ollama)...")
    embeddings = OllamaEmbeddings(model="nomic-embed-text")

    print("Building FAISS index...")
    vs = FAISS.from_documents(chunks, embedding=embeddings)

    Path(INDEX_DIR).mkdir(exist_ok=True)
    vs.save_local(INDEX_DIR)
    print(f"Saved index to: {INDEX_DIR}")

if __name__ == "__main__":
    main()
